[{"content":"1. Machine Learning Machine Learning이란 뭘까? 1959년, 아서 사무엘은 ML을 이렇게 정의했다.\n\u0026ldquo;기계가 일일이 코드로 명시하지 않은 동작을 데이터로부터 학습하여 실핼할 수 있도록 하는 알고리즘을 개발하는 연구 분야이다.\u0026rdquo;\n쉽게 말하면 기계가 스스로 학습하는 것이라고 할 수 있겠다. 그렇다면 기계는 어떤 것을 학습하고 어떻게 학습할 수 있을까? 먼저 학습을 하기 위해서 어떤 요소들이 필요한지 살펴보자. 나는 기계가 학습하기 위해서, 크게 3가지 요소로 나누어 진다고 생각한다.\nData ML 개념 - Supervised Learning, Unsupervised Learning, Reinforcement Learning\u0026hellip; Algorithm - Linear Regression, Tree, Graph, Neural Networks\u0026hellip; 모델은 데이터를 기반으로 학습한다. 데이터가 없다면 모델은 아무것도 할 수가 없다. 데이터의 품질, 양에 따라서 모델의 성능이 크게 좌우된다. 많은 양의 데이터도 중요하지만 데이터의 품질이 중요하다고 생각된다. 데이터가 품질이 좋고 해당되는 분야에 대해서 잘 표현되어 있다면 모델은 이를 통해 좋은 정보와 특징들을 학습하고 우리에게 원하는 답을 찾아 줄 것이다.\nML 개념은 ML에서 가장 중요한 요소이다. 모델의 학습 방식이라고도 할 수 있지만 데이터의 형태라고도 할 수 있다. Supervised learning에서는 Classification, Regression으로 나누어 지고, Unsupervised learning에서는 Clustering, Anomaly Detection 등으로 나누어 진다. 이렇게 데이터의 형태에 따라서 ML을 하는데 있어서 아키텍쳐, 방법, 구성 등 모든 것이 바뀔 수 있다.\n데이터가 주어졌고 데이터의 형태를 우리가 알았다. 이제 마지막으로 Algorithm이 필요하다. Algorithm은 모델이라고도 할 수 있다. 모델은 데이터를 입력받고 예측값을 출력한다. 이 과정 속에서 모델은 지속적으로 학습하고 틀린 문제를 보완할 것이다. 즉 parameter를 업데이트하는 절차를 따른다.\n자 이렇게 ML을 하기 위한 모든 요소들이 갖추어졌다. 그렇다면 Machine Learning에서 Machine은 무엇을 배운다는 것일까? 가장 대표적인 예를 살펴보자\n$$ y=f(x) $$\nML은 입력 데이터 x로부터 출력 y를 잘 예측하는 함수 f를 찾는 과정이라고 할 수 있다. 여기서 머신러닝의 목적은 궁극적으로 f를 찾는 것이다. 데이터셋 $(x_1, y_1), (x_2, y_2), \u0026hellip;, (x_n, y_n)$으로부터 f의 형태와 파라미터를 찾아서, 새로운 x에 대해 y를 잘 예측하는 모델을 만드는 것이다. Linear Regresssion에서는 $f(x)=w*x+b$, Neural Network에서는 $f(x)$가 여러 층의 비선형 함수 조합, Decision Tree에서는 $f(x)$가 조건문 분기 구조가 될 것이다.\n그렇지만 이 $y=f(x)$라는 해석은 기본적으로 Supervised Learning에 해당하는 해석이다. 그리고 Supervised Learning은 ML에서의 핵심 학습 방식이다.\n2. Supervised Learning Supervised Learning의 대표적인 정의를 보자.\nSupervised learning is the process of trying to infer from labeled data the underlying function that produced the labels associated with the data\nSupervised learning은 레이블이 있는 데이터로부터 해당 레이블을 생성한 근본적인 함수를 추론하려는 과정이다.\nlabeled data라는 것은 뭘까? 정답이 있는 데이터를 말하는 것이고 label은 정답이다. 그리고 근본적인 함수는 f를 말하는 것이다. 위에서 말했던 내용과 같다. 결국 labeled data $D={(x_1, y_1), (x_2, y_2), \u0026hellip; ,(x_n, y_n)}$에 대해서 입력 $x$를 받아 출력 $y$(label)을 예측하는 근본적인 함수 f를 학습하고 가장 $y$(label)을 잘 표현하는 f를 찾는 것이다.\n처음에서도 말했듯이 Supervised learning은 크게 Classification, Regression으로 나뉜다. 공통점은 입력 데이터 $x$와 정답 $y$가 주어진 상황에서, 입력으로부터 정답을 예측하는 함수 $f(x)$를 학습하는 것을 목표로 한다.\nClassification은 입력 데이터를 미리 정의된 **클래스(범주)**중 하나로 분류하는 문제이다. 정답 $y$는 이산형(discrete)값이고 예를 들어, 개, 고양이, 양성/음성, 숫자0~9로 표현된다. 문제의 정답은 이렇게 표현되지만 모델이 이를 학습하고 나오는 output은 확률이다. 그러니까 output이 0.5이상이면 개라고 분류하고 0.5 미만이면 고양이라고 분류할 것이다. 확률에 따라서 관측치의 범주를 예측하고 분류한다.\nRegression은 입력 데이터를 기반으로 연속적인 수치값을 예측하는 문제이다. 정답 $y$는 연속형(continuous)값이고 예를 들어, 가격, 온도, 수치 등을 말한다. output은 보통 실수(float)값이다.\nML을 하기 위해서는 어떤 것들이 필요하고 어떤 것을 학습하는지도 알아보았다. 모델은 한 번에 y를 잘 표현하는 f를 바로 찾아내지는 못할것이다. 반복적으로 학습을 하고 예측을 하면서 보완해나간다. 모델의 예측이 정답과 틀렸을 때 어떻게 보완하고 틀렸다는 것을 알 수 있을까? 또는 어떻게 모델의 성능이 좋고 나쁘다는 것을 평가할 수 있을까?\n3. 모델의 성능 평가 기준 먼저 Optimization의 개념을 알아야 한다. Optimization은 어떤 **목적함수(objective function)**의 함수값을 Optimization(maximize 또는 minimize)시키는 parameter(변수)조합을 찾는 문제를 말한다. 여기서 objective function의 구조 및 형태와 이에 따른 찾아야 될 parameter 형태에 따라 다양한 방법이 존재한다. 또한 다루고자 하는 Optimization 문제는 별도의 제약조건이 있는 경우와 없는 경우가 존재한다. $$ \\underset{minimize}{x} f(x) subject to g_i(x)\u0026lt;=0, i=1,\u0026hellip;,m h_j(x)=0, j=1,\u0026hellip;,p $$ where $f:\\mathbb{R}^n \\rightarrow \\mathbb{R} is the objective function to be minimized over the $n$-variable vector $x$ Optimization 문제는 크게 maximization 문제와 minimization 문제로 나눌 수 있는데 objective function이 이윤, 점수(score) 등인 경우에는 maximization 문제가 되고, 비용(cost), 손실(loss), 에러(error) 등인 경우에는 minimization 문제가 된다.\n일반적으로 ML 모델들은 앞서 설명한 기준 함수를 Objective, Cost, Loss Function으로 정의하고 이 기준 함수를 minimize 또는 maximize 하는 방향으로 모델을 학습시킨다.\n4. 우리의 문제 이렇게 ML에 대해서 간단하게 알아보았다. 우리가 어떤 문제를 해결하고 싶어서 데이터를 수집하고 데이터의 형태를 알아보고 분석하고 이에 맞는 모델을 선택하고 어떻게 평가할 지, 어떻게 최적화할 지 선택하고 정하게 될 것이다. 그리고 모델하지만 이 과정 속에서 우리는 항상 생각하고 고려해야되는 문제들이 있다.\n4-1. 데이터의 문제 데이터는 거짓말을 하지 않는다\u0026hellip; 하지만 현실 세계에서의 데이터는 완벽하고 정확하지 않다. 불확실하고 잘못되거나 지저분한 경우가 많다. 또는 label이 없는 경우가 많다. 아주 유명한 말인 쓰레기 심은데 쓰레기 난다(Garbage in, Garbage out; GIGO)라는 말이 있다. 모델의 성공 여부는 데이터 품질에 크게 좌우되다는 것이다.\n먼저, 우리는 품질 좋은 데이터를 얻기 위해, 모델의 성능을 높이기 위해 데이터를 가공하고 정제해야 한다. 데이터 내부에 noise, missing value, 잘못된 labeling 등 이러한 문제들을 해결해야 한다. 데이터의 noise는 관련성이 없거나 무의미한 데이터, 무작위 오류 또는 기본 구조와 추출하고자 하는 진실을 왜곡하는 편차(bias)를 의미한다. missing value(결측치)는 데이터에서 값이 비어있거나 누락된 부분을 말한다. 잘못된 label은 사람의 실수로 인해 발생할 수 있다. 예를 들어 개 이미지가 고양이로 잘못 라벨링되는 등 다양한 방식으로 발생할 수 있다.\n데이터에 편향이 존재할 수 도 있다. 특정 인종, 성별, 지역 등으로 인해 불균형한 분포를 이루고 이에 따라 class imbalance가 발생하고 학습된 모델이 차별적 예측을 할 수 있다.\n데이터 자체가 부족할 수도 있다. 기업 관점에서 자기들이 서비스하는 부분에서 발생하는 데이터는 귀중한 자산이 되고 차별점이 될 것이다. 이에 따라 우리는 데이터 확보가 어려울 수 있고 또는 의료, 법률 등 민감 분야에서 labeled data 확보가 어렵다. 이렇게 되면 작은 데이터셋은 Overfitting, Underfitting 문제와 직결된다.\n데이터에 label이 없다면 우리가 수동으로 labeling 해줄 수 있다. 하지만 labeling 자체가 시간과 비용이 많이 들고 해당 데이터의 도메인 전문가가 필요할 것이다. 수동 라벨링에는 편향성 위험이 발생한다. 이는 labeler가 무의식적으로 한 class를 다른 class보다 선호할 수 있기 때문이다.\n4-2. 모델 학습 관련 문제 우리는 모델을 학습하고 성능을 평가한다. 우리는 모델이 학습하지 않은 데이터에 대해서도 성능이 좋게 나오길 원한다. 바로 일반화(Generalization) 성능이다.\n일반화 성능이 좋다는 것은 모델이 데이터에서 일반적인 패턴과 규칙을 찾아내고 학습해서 새로운 데이터에 대해서도 예측을 잘한다는 것이다. 이것이 머신러닝에서 우리의 궁극적인 목표가 된다.\n하지만 모델이 학습 데이터에서만 너무 잘 맞춰져서 새로운 데이터를 예측을 잘 하지 못하고 성능이 저하되는 현상이 발생한다. Overfitting이 발생하는 것이다. Overfitting은 일반화 성능이 부족한 것이다.\n때로는 모델이 학습 데이터조차 잘 예측하지 못하는 상황이 발생한다. Underfitting을 말하는 것이다. Underfitting은 모델이 너무 단순해서 데이터의 복잡한 패턴을 못 잡는 상황이다.\nhyperparameter에 따른 문제도 있다. hyperparameter는 사람이 직접 조작할 수 있는 parameter를 말한다. learning rate, batch size, optimizer 등 수많은 설정이 성능에 민감하게 작용한다. 물론 이와 관련해서 적절한 hyperparameter를 찾아주는 알고리즘이 많이 나와있지만 많은 알고리즘 속에서도 어떤 알고리즘을 선택할 것인지는 다시 우리의 문제가 된다.\n이런 과정들 전에 애초부터 모델 선택에서 문제가 발생할 수 있다. Tree, SVM, CNN, Transformer 등\u0026hellip; 이 각각에서도 파생되고 생성되는 모델들이 엄청나게 많고 매년 개발되고 연구되고 있다. 본인도 Kaggle, Dacon 등과 같은 AI Competition 사이트에서 대회들을 해보면서 느낀 것은 데이터를 분석하고 전처리가 모두 끝났을 때 이런 모델을 사용하면 좋지 않을까? 매번 예측을 하고 모델을 선택한다. 하지만 예상과는 달리 성능이 안좋을 때가 많다. 어떤 모델에서는 성능이 좋은데 어떤 모델에서는 또 성능이 안좋게 나온다. Decision Tree나 Linear Regression같은 복잡하지 않고 해석이 쉬운 모델들은 우리가 확인하고 왜 성능이 안좋게 나오는지 예상하고 분석할 수 있다. 하지만 Random Forest, Neural Networks, Transformer 점점 복잡하고 최신의 모델로 갈수록 사람이 해석하기 어려워지고 흔히 말하는 black box로 왜 이런 결과가 나오고 왜 성능이 안좋게 나오는 지 알기 힘들게 된다.\n따라서 적절한 모델의 선택은 매우 중요하고 문제의 절반을 차지한다고 생각된다.\n4-3. 계산 자원 문제 마지막으로 자원의 대한 문제가 있다. GPT와 같은 최신의 LLM은 한 번 학습하는 데 몇 천만원이 들고 몇개월이 걸린다고 한다. 모델의 크기와 데이터의 크기가 커질수록 고성능 GPU, TPU, 대용량 메모리가 필요하다.\n대회를 하면서 느낀 점 중에서 또 하나는 확실히 컴퓨팅 파워가 많이 필요하다는 것이다. 먼저 대회에서 주어지는 문제와 데이터를 확인하고 분석한다. 그리고 어떤 기법을 사용할 지 어떤 모델을 사용할 지 시작하기 전에 생각을 하고 코드를 작성한다. 내 설계가 한 번에 좋은 결과를 가져오면 좋겠지만, 그렇지 않은 경우가 태반이다. 이 과정 속에서 수많은 시행착오를 겪고 수정하고 반복하면서 점점 모델의 성능도 좋아지고 LB도 좋아진다. 그렇다면 당연히 고성능 GPU, CPU를 가진 사람들이 더 많이 시행하고 결과를 제출할 것이다. 물론 컴퓨팅 성능이 좋다고해서 무조건적으로 우승하고 점수가 좋게 나오는 것은 아니지만 경쟁을 하면서 학습하고 예측하고 고쳐나가는 과정이 반복되면 점점 격차는 벌어질 것이다.\n5. 결론 최근에는 거대한 모델들의 시간과 비용을 줄이기 위해 많은 최적화 방법들이 연구되고 있다. quantization, LoRA, distillation. Pruning, MoE 등\u0026hellip; 이외에도 엄청나게 많다. 따라서 이런 방법들을 적절히 활용하고 적용해야한다. 무조건 모델의 크기가 크고 복잡하다고 해서 좋은 것이 아니다. 물론 현실의 문제는 복잡하고 현실 세계의 문제를 해결하기 위해 점점 모델이 복잡해지고 거대해지고 있지만, 중요한 것은 내가 해결하고자 하는 문제가 어떤 문제인지 파악하고 문제에 맞는 모델을 선택하고 설계하고 찾아 나가는 것이 중요하다. 뭐든지 적절한 것이 있고 중간이 있는 법이다.\n","permalink":"https://xooyong.github.io/posts/2025-06/2025-06-24-about_machine_learning/","summary":"\u003ch2 id=\"1-machine-learning\"\u003e1. Machine Learning\u003c/h2\u003e\n\u003cp\u003eMachine Learning이란 뭘까? 1959년, 아서 사무엘은 ML을 이렇게 정의했다.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u0026ldquo;기계가 일일이 코드로 명시하지 않은 동작을 데이터로부터 학습하여 실핼할 수 있도록 하는 알고리즘을 개발하는 연구 분야이다.\u0026rdquo;\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e쉽게 말하면 기계가 스스로 학습하는 것이라고 할 수 있겠다. 그렇다면 기계는 어떤 것을 학습하고 어떻게 학습할 수 있을까? 먼저 학습을 하기 위해서 어떤 요소들이 필요한지 살펴보자.\n나는 기계가 학습하기 위해서, 크게 3가지 요소로 나누어 진다고 생각한다.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eData\u003c/li\u003e\n\u003cli\u003eML 개념 - Supervised Learning, Unsupervised Learning, Reinforcement Learning\u0026hellip;\u003c/li\u003e\n\u003cli\u003eAlgorithm - Linear Regression, Tree, Graph, Neural Networks\u0026hellip;\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e모델은 \u003cstrong\u003e데이터\u003c/strong\u003e를 기반으로 학습한다. 데이터가 없다면 모델은 아무것도 할 수가 없다. 데이터의 품질, 양에 따라서 모델의 성능이 크게 좌우된다. 많은 양의 데이터도 중요하지만 데이터의 품질이 중요하다고 생각된다. 데이터가 품질이 좋고 해당되는 분야에 대해서 잘 표현되어 있다면 모델은 이를 통해 좋은 정보와 특징들을 학습하고 우리에게 원하는 답을 찾아 줄 것이다.\u003c/p\u003e","title":"About Machine Learning"},{"content":"","permalink":"https://xooyong.github.io/posts/2025-06/first/","summary":"","title":"My 1st post"}]